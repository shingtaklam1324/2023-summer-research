\documentclass{report}

\usepackage{../../Style}
\usepackage{biblatex}
\addbibresource{../../bibliography.bib}

\DeclareMathOperator{\SU}{SU}
\newcommand{\su}{\mathfrak{su}}

\renewcommand{\sl}{\mathfrak{sl}}

\DeclareMathOperator{\gr}{grad}

\newcommand{\iinner}[1]{\left\langle\!\left\langle #1 \right\rangle\!\right\rangle}

\title{\citetitle{kronheimer_instantons_1990} by \Citeauthor{kronheimer_instantons_1990}}
\author{Shing Tak Lam}

\begin{document}

\maketitle

In this document, we will discuss the paper \cite{kronheimer_instantons_1990}. For concreteness, instead of general Lie groups and Lie algebras, we will focus on the case

\[G = \SU(n) \qquad \mfg = \su(n)\]

which has complexification

\[G^c = \SL(n, \C) \qquad \mfg^c = \sl(n, \C)\]

\tableofcontents

\chapter{Moduli space}

\section{Introduction}

The inner product on \(\su(n)\) is given by \(-\kappa\), where \(\kappa\) is the Killing form. That is,

\[\inner{A, B} = -\tr(AB)\]

Define

\begin{align*}
    \varphi : \su(n) \times \su(n) \times \su(n) &\to \R \\
    \varphi(A_1, A_2, A_3) &= \sum_{j=1}^3 \inner{A_j, A_j} + \inner{A_1, [A_2, A_3]}
\end{align*}

We are interested in studying the gradient flow of \(\varphi\). That is, \(A_1, A_2, A_3 : I \to \su(n)\) such that

\begin{equation}
    \label{eq:gradient-flow}
    (\dot A_1, \dot A_2, \dot A_3) = -\grad \varphi(A_1, A_2, A_3)
\end{equation}

First of all, notice that

\[\varphi(A_1 + H_1, A_2, A_3) = \varphi(A_1, A_2, A_3) + 2\inner{H_1, A_1} + \inner{H_1, [A_2, A_3]}\]

and that \(\inner{A_1, [A_2, A_3]} = \inner{A_2, [A_3, A_1]} = \inner{A_3, [A_1, A_2]}\). Therefore, \cref{eq:gradient-flow} becomes

\begin{equation}
    \label{eq:gradient-flow-system}
    \begin{split}
        \dot A_1 &= -2A_1 - [A_2, A_3] \\
        \dot A_2 &= -2A_2 - [A_3, A_1] \\
        \dot A_3 &= -2A_3 - [A_1, A_2]
    \end{split}
\end{equation}

The critical points of \cref{eq:gradient-flow-system} are triples \((A_1, A_2, A_3)\) satisfying

\[[A_1, A_2] = -2A_3 \quad [A_2, A_3] = -A_1 \quad [A_3, A_1] = -2A_2\]

Recall that the Lie algebra \(\su(2)\) has basis

\[e_1 = \begin{pmatrix}
    -i & 0 \\
    0 & i
\end{pmatrix} \quad e_2 = \begin{pmatrix}
    0 & 1 \\
    -1 & 0
\end{pmatrix} \quad e_3 = \begin{pmatrix}
    0 & -i \\
    -i & 0
\end{pmatrix}\]

satifying the above relations. Therefore, critical points of \cref{eq:gradient-flow-system} correspond to Lie algebra homomorphisms \(\rho : \su(2) \to \su(n)\). From this, we see that at all critical points of \cref{eq:gradient-flow-system}, \(\varphi\) is nonnegative, and it is zero only at \((0, 0, 0)\).

Next, we will identify \(\su(n) \times \su(n) \times \su(n) \cong \rm L(\su(2), \su(n))\), the space of linear maps \(\su(2) \to \su(n)\), sending \((A_1, A_2, A_3)\) to the linear map \(A\) given by \(e_i \mapsto A_i\).

The adjoint action of \(\SU(n)\) on \(\su(n)\) is given by

\[\Ad_g(A) = gAg^{-1}\]

and this induces an action on \(\rm L(\su(2), \su(n))\) by

\[g \cdot A : e_i \mapsto gA_ig^{-1}\]

For any Lie algebra homomorphism \(\rho : \su(2) \to \su(n)\), define

\[C(\rho) = \left\{g \cdot \rho \mid g \in \SU(n)\right\}\]

for the critical manifold of all homomorphisms which are conjugate to \(\rho\) via the adjoint action. For Lie algebra homomorphisms \(\rho_-, \rho_+ : \su(2) \to \su(n)\), define \(M(\rho_-, \rho_+)\) for the space of solutions \(A(t)\) to \cref{eq:gradient-flow-system}, with boundary conditions

\begin{equation}
    \label{eq:boundary-conditions}
    \begin{split}
        \lim_{t\to-\infty}A(t) &\in C(\rho_-) \\
        \lim_{t\to\infty}A(t) &= \rho_+
    \end{split}
\end{equation}

Note that we are considering parametrised trajectories, therefore there is a natural \(\R\)-action sending \(A(t)\) to \(A(t+c)\).

For a Lie algebra homomorphism \(\rho : \su(2) \to \su(n)\), we can extend it to a Lie algebra homomorphism \(\rho : \sl(2, \C) \to \sl(n, \C)\), and define

\[H = \rho\begin{pmatrix}
    1 & 0 \\
    0 & -1
\end{pmatrix}\quad X = \rho\begin{pmatrix}
    0 & 1 \\
    0 & 0
\end{pmatrix} \quad Y = \rho\begin{pmatrix}
    0 & 0 \\
    1 & 0
\end{pmatrix}\]

We will then define \(\mcN(\rho)\) for the nilpotent orbit of \(Y\) in \(\sl(n, \C)\), and the affine subspace

\[S(\rho) = Y + Z(X)\]

where \(Z(X) = \left\{A \in \sl(n, \C) \mid [A, X] = 0\right\}\). Using this, we have

\begin{theorem}
    \label{thm:main}

    For any pair of homomorphisms \(\rho_-, \rho_+\), there is a diffeomorphism

    \[M(\rho_-, \rho_+) \cong \mcN(\rho_-) \cap S(\rho_+)\]
\end{theorem}

If \(\rho_+ = 0\), then \(S(\rho_+) = \sl(n, \C)\), and in this case, we have a diffeomorphism

\[M(\rho_-, 0) \cong \mcN(\rho_-)\]

Moreover, every nilpotent orbit is \(\mcN(\rho)\) for some homomorphism \(\rho : \su(2) \to \su(n)\), which means that we have a description of all nilpotent orbits in \(\sl(n, \C)\).

We will defer the proof of \cref{thm:main} to \cref{sec:proof}, but below, we will provide a sketch proof, which will also function as an outline for the note.

First, we will extend \cref{eq:gradient-flow-system} to a system of equations \cref{eq:gradient-flow-system-extended}. In this case, we have an action of a gauge group. Writing

\[\alpha = \frac{1}{2}(A_0 + iA_1) \qquad \beta = \frac12(A_2 + iA_3)\]

We can split Nahm's equations into a real equation \cref{eq:real-equation} and a complex equation \cref{eq:complex-equation}. In \cref{lem:complex-trajectory-convergence-negative} and \cref{lem:complex-trajectory-convergence-positive}, we show that using the group action, we can assume that the solution to the complex equation takes a given form. In particular, in \cref{prop:complex-trajectory-classification}, we prove that the solutions are parametrised by an element of \(S(\rho_+) \cap \mcN(\rho_-)\).

Thus, we have a bijection between the space of (equivalence classes of) solutions of the complex equation and \(S(\rho_+) \cap \mcN(\rho_-)\). Since each solution to \cref{eq:gradient-flow-system} gives us a solution to the real and complex equations, this gives us a map \(\mcM(\rho_-, \rho_+) \to S(\rho_+) \cap \mcN(\rho_-)\).

Working now with the real equation, using \cref{prop:real-equation-uniqueness}, we can show that the map is injective. On the other hand, in \cref{prop:real-trajectory-existence}, we show that within each equivalence class of complex trajectories, there exists a trajectory which satisfies the real equation. Decomposing into hermitian and anti-hermitian parts, we can use this to recover a solution to the extended equations \cref{eq:gradient-flow-system-extended}. Finally, we use the group action to show that we can take \(A_0 = 0\), and recover a solution to the original equations \cref{eq:gradient-flow-system}. Thus, the map is also surjective.

\section{Complex trajectories}

\subsection{Gauge group}

First of all, we will extend \cref{eq:gradient-flow-system} by considering \(A_0, \dots, A_3 : \R \to \su(n)\), satisfying the equations

\begin{equation}
    \label{eq:gradient-flow-system-extended}
    \begin{split}
        \dot A_1 &= -2A_1 - [A_0, A_1] - [A_2, A_3] \\
        \dot A_2 &= -2A_2 - [A_0, A_2] + [A_1, A_3] \\
        \dot A_3 &= -2A_3 - [A_0, A_3] - [A_1, A_2] \\
    \end{split}
\end{equation}

Define the group

\[\mcG = \left\{g : \R \to \SU(n)\right\}\]

with pointwise operations. Then \(\mcG\) acts \(A = (A_0, \dots, A_3)\) by

\begin{equation}
    \label{eq:action}
    (g \vdot A)(t) = \left(g(t)A_0(t)g(t)^{-1} - \dv{g}{t}(t) \cdot g(t)^{-1}, g(t)A_1(t)g(t)^{-1}, g(t)A_2(t)g(t)^{-1}, g(t)A_3(t)g(t)^{-1}\right)
\end{equation}

For brevity, when clear, we will write this as

\[g \vdot A = (gA_0g^{-1} - \dot g g^{-1}, gA_1g^{-1}, gA_2g^{-2}, gA_3g^{-1})\]

Note that \(\dot g(t) \in \TT_{g(t)}\SU(n) = g(t)\su(n)\), and so \(\dot g(t)g(t)^{-1} \in g(t)\su(n)g(t)^{-1} = \su(n)\). First, we will show that \cref{eq:gradient-flow-system-extended} is invariant under the action \cref{eq:action}. To see this, the transformed right hand side (for the first equation) is

\begin{align*}
    -2gA_1g^{-1} - [gA_0g^{-1} - \dot g g^{-1}, gA_1g^{-1}] - [gA_2g^{-1}, gA_3g^{-1}] &= g(-2A_1 - [A_0, A_1] - [A_2, A_3])g^{-1} + [\dot g g^{-1}, gA_1g^{-1}] \\
    &= g\dot A_1g^{-1} + \dot g A_1 g^{-1} - gA_1g^{-1}\dot g g^{-1} \\
\end{align*}

which is precisely \(\dv{t}(gA_1g^{-1})\). Moreover, in \cref{eq:action}, we can always choose \(g\) to make \(A_0 = 0\), by considering the linear ODE

\[\dot g = gA_0\]

Therefore, we don't change the problem much by considering \cref{eq:gradient-flow-system-extended}. 

\subsection{Complex equations}

Next, we will break the symmetry in the equations, by choosing \(A_1\) to be `special'. More precisely, we will consider \(\alpha, \beta : \R \to \sl(n, \C)\), defined by

\[\alpha = \frac{1}{2}(A_0 + iA_1) \qquad \beta = \frac{1}{2}(A_2 + iA_3)\]

In this case, we have the followiing expressions:

\begin{align*}
    \alpha^* &= \frac{1}{2}(-A_0 + iA_1) \\
    \alpha + \alpha^* &= iA_1 \\
    [\alpha, \alpha^*] &= \frac12i[A_0, A_1] \\
    [\beta, \beta^*] &= \frac12i[A_2, A_3]
\end{align*}

and so the first equation in \cref{eq:gradient-flow-system-extended} can be written as the \emph{real equation}

\begin{equation}
    \label{eq:real-equation}
    \dv{t}(\alpha + \alpha^*) + 2(\alpha + \alpha^*) + 2([\alpha, \alpha^*] + [\beta, \beta^*]) = 0
\end{equation}

and using

\[[\alpha, \beta] = \frac14\left([A_0, A_2] + [A_3, A_1]\right) + \frac14i\left([A_0, A_3] + [A_1, A_2]\right)\]

the second equation in \cref{eq:gradient-flow-system-extended} becomes the \emph{complex equation}

\begin{equation}
    \label{eq:complex-equation}
    \dv{\beta}{t} + 2\beta + 2[\alpha, \beta] = 0
\end{equation}

As above, the real equation is invariant under the action of \(\mcG\). But in this case, the complex equation is invariant under the action of the complex gauge group

\[\mcG^c = \left\{\R \to \SL(n, \C)\right\}\]

via \cref{eq:action}. In particular, the action is given by

\[g \vdot (\alpha, \beta) = \left(g\alpha g^{-1} - \frac{1}{2}\dot g g^{-1}, g\beta g^{-1}\right)\]

and so substituting into \cref{eq:complex-equation}, we get

\begin{align*}
    \dot g \beta g^{-1} + g\dot\beta g^{-1} - g\beta g^{-1}\dot g g^{-1} + 2 g\beta g^{-1} + 2 g[\alpha, \beta]g^{-1} - [\dot g g^{-1}, g\beta g^{-1}] = g\left(\dot\beta + 2\beta + 2[\alpha,\beta]\right)g^{-1}
\end{align*}

\subsection{Complex trajectories}

Let \(\rho_+, \rho_- : \su(2) \to \su(n)\) be Lie algebra homomorphisms. Extend them to Lie algebra homomorphisms \(\sl(2, \C) \to \sl(n, \C)\), and define

\[H_{\pm} = \rho_\pm\begin{pmatrix}
    1 & 0 \\
    0 & -1
\end{pmatrix} \qquad X_\pm = \rho_\pm \begin{pmatrix}
    0 & 1 \\
    0 & 0
\end{pmatrix} \qquad Y_\pm = \rho_\pm \begin{pmatrix}
    0 & 0 \\
    1 & 0
\end{pmatrix}\]

\begin{definition}
    [complex trajectory] A \emph{complex trajectory} associated to \(\rho_+, \rho_-\) is a pair of smooth functions \(\alpha, \beta : \R \to \sl(n, \C)\), which satisfy the complex equation \cref{eq:complex-equation}, and the boundary conditions

    \begin{equation}
        \label{eq:complex-trajectory-boundary-conditions}
        \begin{split}
            \lim_{t \to \infty}2\alpha(t) &= H_+ \\
            \lim_{t \to -\infty}2\alpha(t) &= gH_-g^{-1} \\
            \lim_{t \to \infty}\beta(t) &= Y_+ \\
            \lim_{t \to -\infty}\beta(t) &= gY_-g^{-1}
        \end{split}
    \end{equation}

    for some \(g \in \SU(n)\). Moreover, we require that the convergence in \cref{eq:complex-trajectory-boundary-conditions} is exponential, that is,

    \[\norm{2\alpha(t) - H_+} < Ke^{-\eta t}\]

    for some \(\eta, K > 0\) and so on. Note the choice of norm here does not matter, as all norms on \(\sl(n, \C)\) are equivalent.
\end{definition}

Now define the subgroup \(\mcG^c_0\) of \(\mcG^c\) by

\[\mcG^c_0 = \left\{g \in \mcG^c \mid g \text{ bounded}, \lim_{t \to \infty}g(t) = 1\right\}\]

Using the operator norm, which satisfies \(\norm{gh} \le \norm{g}\norm{h}\), it is clear that \(\mcG_0^c\) is closed under multiplication. Therefore, all we need to show is that it is closed under inverses. One proof is as follows:

By Cayley-Hamilton, we have coefficients \(c_1(t), \dots, c_{n-1}(t)\) such that

\[g(t)^n + c_{n-1}g(t)^{n-1} + \dots + c_1(t)g(t) + 1 = 0\]

Multiplying by \(g(t)^{-1}\), we get

\[g(t)^{-1} = -\left(g(t)^{n-1} + c_{n-1}g(t)^{n-2} + \dots + c_1(t)\right)\]

The \(c_i(t)\) are the elementary symmetric functions in the eigenvalues of \(g(t)\), and the eigenvalues of \(g(t)\) are bounded, since any eigenvalue \(\lambda\) of \(g(t)\) necessarily satisfies \(\abs{\lambda} \le \norm{g(t)}\). Therefore, the coefficients on the right hand side are bounded. Hence by the triangle inequality, we have a bound on \(\norm{g(t)^{-1}}\).

\begin{definition}
    [equivalent] We say that two complex trajectories \((\alpha, \beta)\) and \((\alpha', \beta')\) are \emph{equivalent} if there exists \(g \in \mcG^c_0\) such that

    \[(\alpha', \beta') = g \vdot (\alpha, \beta)\]

    i.e. they are in the same \(\mcG_0^c\) orbit.
\end{definition}

\subsection{Classification of complex trajectories}

First of all, note that under the \(\mcG^c\) action, we can always make \(\alpha = 0\). In particular, we need

\[\dot g = 2g\alpha\]

Assuming this, the complex equation \cref{eq:complex-equation} becomes

\[\dv{\beta}{t} + 2\beta = 0\]

which has solution

\[\beta(t) = e^{-2t}\beta_0\]

for some \(\beta_0\). Therefore, the only local invariant under the \(\mcG^c\) (and \(\mcG^c_0\)) action is the conjugacy class of \(\beta_0\). Reversing the \(\mcG^c\) action, we find that a generic local solution is

\begin{align*}
    \alpha = \frac{1}{2}g^{-1}\dot g \\
    \beta = e^{-2t}g^{-1}\beta_0g
\end{align*}

As a consequence of this, we have

\begin{lemma}
    \label{lem:complex-trajectory-equal}

    If \((\alpha, \beta)\) and \((\alpha', \beta')\) are complex trajectories which are equal outside of some compact set \(K \subseteq \R\), then \((\alpha, \beta)\) and \((\alpha', \beta')\) are equivalent.
\end{lemma}

\begin{proof}
    Without loss of generality, we may assume \(K = [-M, M]\) for some \(M > 0\). Using the \(\mcG^c\) action, we may assume that

    \[\alpha(t) = 0 \qquad \beta(t) = e^{-2t}\beta_0\]

    Now let \(g \in \mcG^c\) be such that

    \[g \vdot (\alpha', \beta') = (0, e^{-2t}\beta_0')\]

    In particular, as

    \[\dot g = 2g\alpha'\]

    \(\dot g = 0\) for \(t \notin [-M, M]\), and so \(g\) is constant outside of \([-M, M]\). Say \(g = g_-\) for \(t < -M\) and \(g = g_+\) for \(t > M\). By left multiplication by \(g_+^{-1}\), we can assume \(g_+ = 1\). This means that for \(t > M\), \(e^{-2t}\beta'(t) = e^{-2t}\beta_0'\). But in this case \(\beta = \beta'\), so \(\beta_0 = \beta_0'\). Hence \(g \cdot (\alpha', \beta') = (\alpha, \beta)\), and so they are equivalent.
\end{proof}

\begin{lemma}
    \label{lem:complex-trajectory-convergence-negative}

    Let \((\alpha, \beta)\) be a solution of the complex equation \cref{eq:complex-equation}, satisfying the boundary equations \cref{eq:complex-trajectory-boundary-conditions} at \(t \to -\infty\). That is,

    \[\lim_{t\to-\infty}2\alpha(t) = gH_-g^{-1} \qquad \lim_{t \to -\infty}\beta(t) = gY_-y^{-1}\]

    with exponential convergence. Then there exists a gauge transformation \(g_- : \R \to \SL(n, \C)\) such that \((\alpha', \beta') = g_-\vdot(\alpha, \beta)\) is the constant solution

    \[2\alpha' = H_- \qquad \beta' = Y_-\]

    and \(g_-(t)\) converges as \(t \to -\infty\).
\end{lemma}

\begin{proof}
    By conjugation, without loss of generality \(g = 1\). Considering the ODE

    \begin{equation*}
            \dot g_0 = 2g_0\alpha - H_-g_0
    \end{equation*}

    We can find \(g_0\) such that

    \[H_- = 2g_0\alpha g_0^{-1} - \dot g_0 g_0^{-1}\]

    with the boundary condition \(g_0(t) \to 1\), as \(t \to -\infty\), since \(2\alpha(t) \to H_-\) exponentially. \textbf{TODO: Check this, see email.}

    Using this, we get a transformed solution \((\alpha'', \beta'') = g_0\vdot(\alpha,\beta)\), with \(2\alpha'' = H_-\). In this case, the complex equation becomes

    \[\dv{\beta''}{t} + 2\beta'' + [H_-, \beta''] = 0\]

    Trying the ansatz

    \begin{align*}
        \beta''(t) &= e^{-2t}\Ad_{f(t)}(\omega) = e^{-2t}f\omega f^{-1} \\
        f(t) &= \exp(Xt)
    \end{align*}

    We have that

    \[\dot f = Xf\]

    and so

    \begin{align*}
        \dot\beta'' &= -2e^{-2t}f\omega f^{-1} + e^{-2t}\dot f \omega f^{-1} - e^{-2t}f\omega f^{-1}\dot f f^{-1} \\
        &= -2\beta'' + X\beta'' - \beta'' X
    \end{align*}

    Therefore, the complex equation becomes

    \begin{align*}
        \dot\beta'' + 2\beta'' + H_-\beta'' - \beta''H_- = -2\beta'' + X\beta'' - \beta''X + 2\beta'' + H_-\beta'' - \beta''H_- = [X + H_-, \beta'']
    \end{align*}

    Hence setting \(X = -H_-\), we get a solution. By dimensionality arguments, this is the general solution.

    Using the composition

    % https://q.uiver.app/#q=WzAsMyxbMCwwLCJcXHNsKDIsIFxcQykiXSxbMiwwLCJcXHNsKG4sIFxcQykiXSxbNCwwLCJcXGdsKFxcc2wobiwgXFxDKSkiXSxbMCwxLCJcXHJob18tIl0sWzEsMiwiXFxhZCJdXQ==
\[\begin{tikzcd}[ampersand replacement=\&]
	{\sl(2, \C)} \&\& {\sl(n, \C)} \&\& {\gl(\sl(n, \C))}
	\arrow["{\rho_-}", from=1-1, to=1-3]
	\arrow["\ad", from=1-3, to=1-5]
\end{tikzcd}\]

    We get a representation of \(\sl(2, \C)\) on \(\sl(n, \C)\). Therefore, we have a decomposition

    \[\sl(n, \C) = \bigoplus_{k \in \Z}V_k\]

    where \(V_\lambda\) is the \(\lambda\)-eigenspace of \(\ad(H_-)\). Since we want \(\beta'' \to Y_-\) as \(t \to -\infty\), we will try the ansatz \(\omega = Y_- + \delta\). By linearity, we can first compute the case of \(\omega = Y_-\).

    First of all, notice that we also have that \(\dot f = f X = -fH_-\), and so in this case

    \begin{align*}
        \dot\beta'' &= -2e^{-2t}f Y_- f^{-1} - e^{-2t}f H_- Y_- f^{-1} + fY_-f^{-1}fH_-f^{-1} \\
        &= -2\beta'' - f[H_-, Y_-]f^{-1} \\
        &= 0
    \end{align*}

    as \([H_-, Y_-] = \rho_-([H, Y]) = \rho_-(-2Y) = -2Y_-\). Therefore, as \(\beta''(0) = Y_-\) in this case, it is constant. Now by linearity, say \(\delta = \sum_k \delta_k\), where \(\delta_k \in V_k\). Then for \(\omega = \delta_k\),

    \[\dot\beta'' = -2\beta'' - f[H_-, \delta_k]f^{-1} = -(2+k)\beta''\]

    This gives the solution

    \[\beta''(t) = e^{-(2+k)t}\beta''(0) = e^{-(2+k)t}\delta_k\]

    Since we require \(\beta''(t) \to 0\) as \(t \to -\infty\) in this case, we need \(-(2+k) > 0\), i.e. \(k < -2\). Hence the general solution in this case is

    \[\beta''(t) = Y_- + e^{-2t}\exp(-H_-t)\delta\exp(H_-t)\]

    where \(\delta \in \bigoplus\limits_{k < -2}V_k\). Now notice that \(g_0\) from earlier was not uniquely determined. We can still act on the solution by a gauge transformation \(g_1\), which preserves \(2\alpha'' = H_-\), and approaches \(1\) at \(t \to -\infty\). That is, we have the equation

    \[H_- = g_1H_-g_1^{-1} - \dot g_1 g_1^{-1}\]

    which we can rearrange to

    \[\dot g_1 = g_1H_- - H_- g_1\]

    Trying the ansatz

    \begin{align*}
        g_1(t) &= f(t)\sigma f(t)^{-1} \\
        f(t) &= \exp(-H_- t)
    \end{align*}

    for \(\sigma \in \SL(n, \C)\), we find that this gives the general solution for the equation. For the boundary condition, suppose further that \(\sigma = \exp(\gamma)\), for some \(\gamma \in \sl(n, \C)\). Define

    \[h_t(s) = f\exp(s\gamma)f^{-1}\]

    and note that \(g_1(t) = h_t(1)\). Then

    \begin{align*}
        \dv{h_t}{s}(s) &= f \exp(s\gamma)\gamma f^{-1} \\
        &= h_t(s) \cdot f \gamma f^{-1}
    \end{align*}

    Set \(\varphi(t) = f\gamma f^{-1}\), then we have that

    \[\dot\varphi = -f[H, \gamma]f^{-1}\]

    This equation is linear in \(\gamma\), and so for simplicity, we will assume \(\gamma \in V_k\). In this case, \(\dot\varphi = -k\varphi\), and so \(\varphi(t) = e^{-kt}\gamma\). Substituting this in, we get that

    \[\dv{h_t}{s} = e^{-kt}h_t \cdot \gamma\]

    and so, integrating this equation, we find that

    \[h_t(s) = \exp(se^{-kt}\gamma) \implies g_1(t) = \exp(e^{-kt}\gamma)\]

    Thus, for \(g_1 \to 1\) as \(t \to -\infty\), we must have \(k < 0\). Therefore, the general solution is

    \[g_1(t) = \exp(-H_-t)\exp(\gamma)\exp(H_-t)\]

    where \(\gamma \in \bigoplus\limits_{k < 0}V_k\). Therefore, if we consider \((\alpha', \beta') = g_1 \cdot (\alpha'', \beta'')\), we would get that \(2\alpha' = H_-\), and

    \[\beta'(t) = Y_- + e^{-2t}\exp(-H_-t)(\exp(\gamma)(Y_- + \delta)\exp(-\gamma) - Y_-)\exp(H_-t)\]

    Therefore, all that remains to show is that for all \(\delta \in \bigoplus\limits_{k < -2}V_k\), there exists \(\gamma \in \bigoplus\limits_{k < 0}V_k\) such that

    \[\exp(\gamma)(Y_- + \delta)\exp(-\gamma) - Y_- = 0\]

    We will use the implicit function theorem for this. Expand the left hand side near \(\gamma = \delta = 0\), the terms linear in \(\gamma, \delta\) are

    \[f(\gamma, \delta) = \delta + \gamma Y_- - Y_-\gamma = \delta - [Y_-, \gamma]\]

    From the representation theory of \(\sl(2, \C)\), we have a linear map

    \[[Y_-, \cdot] : \bigoplus_{k < 0}V_k \to \bigoplus_{k < -2}V_k\]
    
    and so we have a map 

    \[f : \bigoplus_{k < 0}V_k \oplus \bigoplus_{k < -2}V_k \to \bigoplus_{k < -2}V_k\]
    
    The map \(\gamma \mapsto f(\gamma, 0)\) is surjective, for example by decomposing \(\sl(n, \C)\) as a direct sum of \(\sl(2, \C)\) representations. Therefore if we have a decomposition

    \[\bigoplus_{k < 0}V_k = K \oplus W\]

    where \(K = \ker(f(\cdot, 0))\), then the map \(\hat f : W \to \bigoplus\limits_{k < -2}V_k\), given by \(\hat f(\gamma) = f(\gamma, 0)\), is an isomorphism. We can then apply the implicit function theorem to

    \begin{align*}
        F : \left(\bigoplus_{k < -2}V_k \oplus K\right) \oplus W &\to \bigoplus_{k < -2}V_k \\
        F((\delta, k), \gamma') &= \exp((\gamma', k))(Y_- + \delta)\exp(-(\gamma', k)) - Y_-
    \end{align*}

    which then gives us a neighbourhood \(U\) of \(0\) in \(\bigoplus\limits_{k < -2}V_k\), and a neighbourhood \(V\) of \(0\) in \(W\), and a map \(g : U \times V \to W\) such that

    \[F(x, g(x)) = 0\]

    for all \(x \in U \times V\). Therefore, for \(\delta \in U\), setting \(\gamma = g(\delta, 0)\) gives the required result. Finally, we will use homogeneity to extend the result to all of \(\bigoplus \limits_{k < -2}V_k\). First of all, we note that the condition is invariant under the substitution

    \begin{align*}
        \gamma &= f\hat\gamma f^{-1} \\
        \delta &= e^{-2t}f\hat\delta f^{-1}
    \end{align*}

    where \(f(t) = \exp(-H_-t)\), since we have that \(Y_- = e^{-2t}fY_-f^{-1}\), and that \(\exp(f\hat\gamma f^{-1}) = f\exp(\hat\gamma)f^{-1}\). Now suppose \([H, v] = mv\), and let \(\varphi = fvf^{-1}\). Then

    \begin{align*}
        \dot\varphi &= f\dot vf^{-1} - fvf^{-1}\dot f f^{-1} \\
        &= -fHvf^{-1} + fvHf^{-1} \\
        &= -mfvf^{-1} \\
        &= -m\varphi
    \end{align*}

    Hence \(\varphi(t) = e^{-mt}v\). Therefore in the limit \(t \to -\infty\) (as \(m < 0\)), we have that \(\gamma \to 0\), and so we can apply the result for small \(\delta\).
\end{proof}

There is a very similar result for the limit at \(t \to \infty\).

\begin{lemma}
    \label{lem:complex-trajectory-convergence-positive}

    Let \((\alpha, \beta)\) be a solution of the complex equation \cref{eq:complex-equation} satisfying the boundary equations \cref{eq:boundary-conditions} at \(t \to \infty\). That is,

    \[\lim_{t \to \infty}2\alpha(t) = H_+ \qquad \lim_{t \to \infty}\beta(t) = Y_+\]

    with exponential convergence. Then there exists a unique gauge transformation \(g_+ : \R \to \SL(n, \C)\), with \(g_+(t) \to 1\) as \(t \to \infty\), such that the transformed solution \((\alpha', \beta') = g_+ \vdot (\alpha, \beta)\) satisfies

    \[2\alpha' = H_+ \qquad \beta'(0) \in S(\rho_+)\]
\end{lemma}

\begin{proof}
    The proof is very similar to the previous lemma. We find a gauge transformation \(g_0\), approaching \(1\) as \(t \to \infty\), such that \((\alpha'', \beta'') = g\vdot (\alpha, \beta)\) satisfies

    \begin{align*}
        2\alpha'' &= H_+ \\
        \beta''(t) &= Y_+ + e^{-2t}\exp(-H_+t)\epsilon\exp(H_+t)
    \end{align*}

    with

    \[\epsilon \in \bigoplus_{k > -2}V_k\]

    where in this case, \(V_k\) is the \(k\)-eigenspace of \(\ad(H_+)\). As above, we have a further choice of gauge transformation \(g_1\) of the form

    \[g_1(t) = \exp(-H_+t)\exp(\gamma)\exp(H_+t)\]

    where \(\gamma \in \bigoplus_{i > 0}V_k\). Using this, the solution becomes

    \[\beta''(t) = Y_+ + e^{-2t}\exp(-H_+t)(\exp(\gamma)(Y_+ + \epsilon)\exp(-\gamma) - Y_+)\exp(H_+t)\]

    Recall that \(S(\rho_+) = Y_+ + Z(X_+)\). Therefore, we need to show that for each \(\epsilon \in \bigoplus\limits_{k > -2}V_k\), there exists \(\gamma \in \bigoplus\limits_{k > 0}V_k\) such that

    \[\exp(\gamma)(Y_+ + \epsilon)\exp(-\gamma) - Y_+ \in Z(X_+)\]

    Expanding the left hand side near \(\gamma = \epsilon = 0\), to first order we have

    \[f(\gamma, \epsilon) = \epsilon - [Y_+, \gamma]\]

    In this case, we have a linear map

    \[[Y_+, \cdot] : \bigoplus_{k > 0}V_k \to \bigoplus_{k > -2}V_k\]

    which is injective, and its image satisfies

    \[\bigoplus_{k > -2} V_k = \Im([Y_+, \cdot]) \oplus Z(X_+)\]

    Therefore, for each \(\epsilon\), there exists a unique \(\gamma\) such that \(f(\gamma, \epsilon) \in Z(X_+)\). Hence the linearisation has a unique solution, and so by the implicit function theorem, for \(\epsilon\) sufficiently small, there exists \(\gamma\) such that \(\exp(\gamma)(Y_+ + \epsilon)\exp(-\gamma) - Y_+ \in Z(X_+)\). Finally, we can use homogeneity to extend the result to all of \(\bigoplus\limits_{k > -2}V_k\) as above.
\end{proof}

Now let \((\alpha', \beta')\) be a solution of the complex equation \cref{eq:complex-equation} satisfying the boundary conditions \cref{eq:boundary-conditions}. Define a gauge transformation \(g : \R \to \SL(n, \C)\) via

\begin{equation}
    g(t) = \begin{cases}
        g_-(t) & t \le 0 \\
        g_+(t) & t \ge 1
    \end{cases}
\end{equation}

and smooth on all of \(\R\). Then \(g(t)\) is bounded, since \(g_-\) and \(g_+\) are, as they converge in the limit \(t \to \pm\infty\). Therefore, \(g \in \mcG_0^c\), and \((\alpha, \beta) = g \vdot (\alpha', \beta')\) is given by

\begin{equation}
    \label{eq:complex-trajectory-form}
    \begin{split}
        \alpha(t) &= \begin{cases}
            \frac{1}{2}H_- & t \le 0 \\
            \frac{1}{2}H_+ & t \ge 1
        \end{cases} \\
        \beta(t) &= \begin{cases}
            Y_- & t \le 0 \\
            Y_+ + e^{-2t}\exp(-H_+t)\epsilon\exp(H_+t) & t \ge 1
        \end{cases}
    \end{split}
\end{equation}

and hence every complex trajectory is equivalent to one of this form. Moreover, we can choose \(\epsilon\) such that \(Y_+ + \epsilon \in S(\rho_+)\), and in this case, \(\epsilon\) is uniquely determined.

Since \((\alpha, \beta)\) is locally equivalent to the constant solution \((-\frac{1}{2}H_-, Y_-)\), the element \(Y_+ + \epsilon\) must be conjugate to \(Y_-\) in \(\sl(n, \C)\). That is, \(Y_+ + \epsilon \in \mcN(\rho_-)\). Conversely, given \(Y_+ + \epsilon \in S(\rho_+) \cap \mcN(\rho_-)\), we can always find a solution satisfying \cref{eq:complex-trajectory-form}.

\begin{proposition}
    \label{prop:complex-trajectory-classification}

    The equivalence classes of complex trajectories associated to \(\rho_+, \rho_-\) are parametrised by \(S(\rho_+) \cap \mcN(\rho_-)\).
\end{proposition}

\begin{proof}
    We have already seen that each trajectory is equivalent to one in the form \cref{eq:complex-trajectory-form}, which is parametrised by the element \(Y_+ + \epsilon \in S(\rho_+) \cap \mcN(\rho_-)\). Using \cref{lem:complex-trajectory-equal}, we see that two trajectories which are equal outside of \([0, 1]\) are equivalent. Therefore, the equivalence classes are parametrised by \(Y_+ + \epsilon \in S(\rho_+) \cap \mcN(\rho_-)\).
\end{proof}

\section{Nahm's equations}

\label{sec:nahm}

Consider the change of variables

\[T_i = e^{2t}A_i \qquad s = -\frac12e^{-2t}\]

Using this, \cref{eq:gradient-flow-system} becomes

\begin{align*}
    \dv{T_1}{s} &= -[T_2, T_3] \\
    \dv{T_2}{s} &= -[T_3, T_1] \\
    \dv{T_3}{s} &= -[T_1, T_2]
\end{align*}

which are Nahm's equations. The same change of variables also transforms \cref{eq:gradient-flow-system-extended} into 

\begin{align*}
    \dv{T_1}{s} + [T_0, T_1] + [T_2, T_3] &= 0 \\
    \dv{T_2}{s} + [T_0, T_2] + [T_3, T_1] &= 0 \\
    \dv{T_3}{s} + [T_0, T_3] + [T_1, T_2] &= 0 \\
\end{align*}

Using this, we can also consider the action of the gauge group on this system. Recall that the action is given by \cref{eq:action}, which is:

\[g \vdot A = (gA_0g^{-1} - \dot g g^{-1}, gA_1g^{-1}, gA_2g^{-1}, gA_3g^{-1})\]

Note that

\[\dot g = \dv{g}{t} = \dv{g}{s}\dv{s}{t} = e^{-2t}\dv{g}{s}\]

In this case, the gauge group action becomes

\begin{align*}
    g \vdot T &= g \vdot (e^{-2t}T_0, e^{-2t}T_1, e^{-2t}T_2, e^{-2t}T_3) \\
    &= \left(e^{-2t}gT_0g^{-1} - e^{-2t}\dv{g}{s} g^{-1}, e^{-2t}gT_1g^{-1}, e^{-2t}gT_2g^{-1}, e^{-2t}gT_3g^{-1}\right) \\
    &= \left(gT_0g^{-1} - \dv{g}{s}g^{-1}, gT_1g^{-1}, gT_2g^{-1}, gT_3g^{-1}\right)
\end{align*}

This is the same as the action as in \cite[Equation 1.6]{donaldson_nahms_1984}. Finally, we can consider the \(\SL(n, \C)\) valued paths

\[\tilde\alpha = e^{2t}\alpha = \frac{1}{2}(T_0 + iT_1) \qquad \tilde\beta = e^{2t}\beta = \frac12(T_2 + iT_3)\]

In this case the real and complex equations become

\begin{align}
    \label{eq:nahm-real-equation}
    \dv{s}(\tilde\alpha + \tilde\alpha^*) + 2([\tilde\alpha, \tilde\alpha^*] + [\tilde\beta, \tilde\beta^*]) &= 0 \\
    \dv{\tilde\beta}{s} + 2[\tilde\alpha, \tilde\beta] &= 0 \nonumber
\end{align}

With all of this in mind, this allows us to use the results from \cite{donaldson_nahms_1984}.

\section{Real equation}

Recall the real equation \cref{eq:real-equation},

\[\hat F(\alpha, \beta) = \dv{t}(\alpha + \alpha^*) + 2(\alpha + \alpha^*) + 2([\alpha, \alpha^*] + [\beta, \beta^*]) = 0\]

Write \((\alpha', \beta') = g \vdot (\alpha, \beta)\), and we will regard \(\hat F(\alpha', \beta') = 0\) as an equation for \(g\). First of all, notice that the real equation is invariant under the action of \(\mcG\), and so the action of \(g\) only depends on the corresponding path

\[\tilde g : \R \to \SL(n, \C) / \SU(n) = \mcH\]

From the polar decomposition of \(\SL(n, \C)\), we can write any \(A \in \SL(n, \C)\) uniquely as \(A = UP\), where \(U \in \SU(n)\) and \(P\) is hermitian, with positive eigenvalues and \(\det(P) = 1\). Hence we can choose

\[\mcH = \left\{A \in \SL(n, \C) \mid A \text{ hermitian, with positive eigenvalues}\right\}\]

For each \(g\), we define \(h = h(g) = g^*g\), which gives us a path \(h : \R \to \mcH\).

\subsection{Uniqueness}

\begin{lemma}
    \label{lem:gauge-exists-with-dirichlet}
    Suppose \((\alpha, \beta)\) satisfies the complex equation on an interval \([-N, N]\). Then for any \(h_-, h_+ \in \mcH\), there exists \(g : [-N, N] \to \SL(n, \C)\) continuous and smooth on the interior, with \(h = h(g)\) satisfying

    \[h(-N) = h_- \qquad h(N) = h_+\]

    and such that \((\alpha', \beta') = g \vdot (\alpha, \beta)\) satisfies the real equation \(\hat F(\alpha', \beta') = 0\) on \([-N, N]\).
\end{lemma}

\begin{proof}
    See \cite[Proposition 2.8]{donaldson_nahms_1984}. The main idea is that the real equation (for Nahm's equations) is the Euler-Lagrange equations for a functional, and so the result follows by the direct method of the calculus of variations. To get the result, we apply \cite[Proposition 2.8]{donaldson_nahms_1984} with

    \[\text{`}\alpha\text{'} := \tilde \alpha = e^{2t}\alpha \qquad \text{`}\beta\text{'} = \tilde\beta = e^{2t}\beta\]

    and modify the interval \([\epsilon, 2-\epsilon]\) to \([-N, N]\). The work in \cref{sec:nahm} shows that \(g\) has the required properties.
\end{proof}

Now for \(h \in \mcH\), with eigenvalues \(\lambda_1, \dots, \lambda_k\), define

\[\Psi(h) = \log\max(\lambda_i)\]

Since \(\det(h) = 1\), \(\Psi(h) = 0\) if and only if \(h = 1\). Moreover, if \(h(t)\) is continuous, then \(\Psi(h(t))\) is as well.

\begin{lemma}
    \label{lem:differential-inequality}

    If \((\alpha', \beta') = g \vdot (\alpha, \beta)\) over some interval in \(\R\), then with \(h = g^*g\),

    \[\dv[2]{t}\Psi(h) + 2\dv{t}\Psi(h) \ge -2\left(\abs{\hat F(\alpha, \beta)} + \abs{\hat F(\alpha', \beta')}\right)\]

    weakly. Note the norm on the right hand side is defined using the Killing form.
\end{lemma}

\begin{proof}
    We want to use \cite[Lemma 2.10]{donaldson_nahms_1984}. First, we will write the left hand side in terms of \(s\). In this case, we have

    \begin{align*}
        \dv{\Psi}{s} &= \dv{\Psi}{t}\dv{t}{s} \\
        \dv[2]{\Psi}{s} &= \dv[2]{\Psi}{t}\left(\dv{t}{s}\right)^2 + \dv{\Psi}{t}\dv[2]{t}{s} \\
        &= e^{4t}\left(\dv[2]{\Psi}{t} + 2\dv{\Psi}{t}\right) 
    \end{align*}

    Next, note that the real equation for Nahm's equations, \cref{eq:nahm-real-equation}, is

    \begin{align*}
        \dv{s}(\tilde\alpha + \tilde\alpha^*) + 2([\tilde\alpha, \tilde\alpha^*] + [\tilde\beta, \tilde\beta^*]) &=\dv{t}(e^{2t}(\alpha + \alpha^*))\dv{t}{s} + 2e^{4t}([\alpha, \alpha^*] + [\beta, \beta^*]) \\
        &= e^{4t}\left(\dv{t}(\alpha + \alpha^*) + 2(\alpha + \alpha^*) + 2([\alpha, \alpha^*] + [\beta, \beta^*])\right)
    \end{align*}

    Therefore, compared to \cite[Lemma 2.10]{donaldson_nahms_1984}, we have a factor of \(e^{4t}\) on both sides, which is a positive function. Therefore, the result follows.
\end{proof}

\begin{proposition}
    \label{prop:real-equation-uniqueness}
    Suppose \((\alpha', \beta')\) and \((\alpha'', \beta'')\) are equivalent complex trajectories, satisfying the real equation \cref{eq:real-equation}, then \((\alpha'', \beta'') = g\vdot(\alpha', \beta')\) for some \(g \in \mcG\), i.e. \(g : \R \to \SU(n)\), with \(g(t) \to 1\) as \(t \to \infty\).
\end{proposition}

\begin{proof}
    Suppose \((\alpha', \beta')\) and \((\alpha'', \beta'') = g\vdot(\alpha', \beta')\) both satisfy the real equation. Setting \(h = h(g)\) and \(\Psi = \Psi(h)\), we find that

    \[\ddot \Psi + 2\dot\Psi \ge 0\]

    Using the same computation as in the previous lemma, this implies that

    \[\dv[2]{\Psi}{s} \ge 0\]

    and so \(\Psi(s)\) is convex. The other conditions transform to \(\Psi : (-\infty, 0) \to \R\) as: \(\Psi(s) \to 0\) as \(s \to 0\), \(\Psi(s)\) bounded and nonnegative. This then implies that \(\Psi\) must be identically zero. Hence \(h = 1\), and so \(g^*g = 1\). That is, \(g\) takes values in \(\SU(n)\).
\end{proof}

\subsection{Existence}

Let \((\alpha, \beta)\) be a solution to the complex equations. We can assume without loss of generality that \((\alpha, \beta)\) is in the form \cref{eq:complex-trajectory-form}.

\begin{lemma}
    \label{lem:existence-bound}

    If \((\alpha, \beta)\) are in the form as in \cref{eq:complex-trajectory-form}, and \(\epsilon \in Z(X_+)\), then

    \[
    \begin{cases}
        \hat F(\alpha, \beta) = 0 & \text{on }\Ioc{-\infty, 0} \\
        \abs{\hat F(\alpha, \beta)} \le Ce^{-4t} & \text{on }\Ico{0, \infty}
    \end{cases}\]
\end{lemma}

\begin{proof}
    In both cases, since \(\rho_{\pm}\) are representations of \(\su(2)\), we have that

    \begin{align*}
        H_{\pm}^* &= H_{\pm} \\
        X_{\pm}^* &= Y_{\pm} \\
        Y_{\pm}^* &= X_{\pm} \\
    \end{align*}

    Thus, in the first case, we have

    \[2H_- + 2[Y_-, X_-] = 0\]

    which is true as \(\rho_-\) is a representation of \(\sl(2, \C)\). For the second case, let

    \[\epsilon(t) = e^{-2t}\exp(-H_+t)\epsilon\exp(H_+t)\]

    and we have that

    \[\alpha = \frac12H_+ \qquad \beta(t) = Y_+ + \epsilon(t)\]

    Computing each part, we have

    \begin{align*}
        \alpha + \alpha^* &= H_+ \\
        [\alpha, \alpha^*] &= 0 \\
        [\beta, \beta^*] &= [Y_+ + \epsilon(t), Y_+^* + \epsilon(t)^*] \\
        &= -H_+ + [\epsilon(t), X_+] + [Y_+, \epsilon(t)^*] + [\epsilon(t), \epsilon(t)^*] \\
        &= -H_+ + 2[\epsilon(t), X_+] + [\epsilon(t), \epsilon(t)^*]
    \end{align*}

    We want to show that \([\epsilon(t), X_+] = 0\). Set \(f = \exp(-H_+t)\), then this is equivalent to showing \(\varphi = 0\), where \(\varphi(t) = [\epsilon, e^{2t}f^{-1}X_+ f]\). Since \(\varphi(0) = 0\), as \(\epsilon \in Z(X_+)\), suffices to show \(\dot\varphi = 0\). Computing,

    \begin{align*}
        \dot\varphi &= [\epsilon, 2e^{-2t}f^{-1}X_+ f - e^{2t}f^{-1}H_+X_+ f + e^{2t}f^{-1}X_+ H_+f] \\
        &= 0
    \end{align*}

    as \([H, X] = 2X\). Therefore, we have that \(\hat F(\alpha, \beta) = 2[\epsilon(t), \epsilon(t)^*]\). In this case, we have that \(\abs{\epsilon(t)} = e^{-2t}\abs{\epsilon}\), and so using the fact that the norm is (up to a constant) submultiplicative, we have that

    \[\abs{\hat F(\alpha, \beta)} \le Ce^{-4t}\]

    Since \(\hat F\) is bounded on \([0, 1]\), making \(C\) larger if necessary, we have that \(\abs{\hat F(\alpha, \beta)} \le Ce^{-4t}\) on \(\Ico{0, \infty}\). 
\end{proof}

Using \cref{lem:gauge-exists-with-dirichlet}, for each \(N \in \N\), we can find a complex gauge transformation \(g_N : [-N, N] \to \SL(n, \C)\), such that \(g_N \vdot (\alpha, \beta)\) satisfies the real equation, and \(h_N = g_N^*g_N\) satisfies the Dirichlet boundary condition \(h_N(\pm N) = 1\). We will now show that the \(h_N\) have a smooth limit as \(N \to \infty\).

\begin{lemma}
    \label{lem:uniform-bound}
    Let \(C\) be the constant from \cref{lem:existence-bound}. Define the \(C^1\) function \(\psi : \R \to \R\) by

    \[\psi(t) = \begin{cases}
        C/4 & t \le 0 \\
        Ce^{-2t}/2 - Ce^{-4t}/4 & t \ge 0
    \end{cases}\]

    Then for all \(N\), we have \(\Psi(h_N) < \psi\) on \([-N, N]\).
\end{lemma}

\begin{proof}
    We have that

    \[\ddot \psi + 2\dot\psi = \begin{cases}
        0 & t < 0 \\
        -2Ce^{-4t} & t > 0
    \end{cases}\]

    and \cref{lem:differential-inequality} and \cref{lem:existence-bound} gives us that

    \[\ddot\Psi + 2\dot\Psi \ge -2\abs{\hat F(\alpha, \beta)} \ge \begin{cases}
        0 & t \le 0 \\
        -2Ce^{-4t} & t \ge 0
    \end{cases}\]

    Therefore, we have that \((\ddot\Psi - \ddot\psi) + 2(\dot\Psi - \dot\psi) \ge 0\). Using the change of variables \(s = -\frac12e^{-2t}\) as before, we find that

    \[\dv[2]{s}(\Psi - \psi) \ge 0\]

    That is, \(\Psi - \psi\), as a function of \(s\), is convex. Therefore, by the maximum principle for convex functions, the maximum value of \(\Psi - \psi\) is attained at one of the end points. By assumption, \(h_N(\pm N) = 1\), and so \(\Psi(\pm N) = 0\). Thus, \(\Psi(-N) - \psi(-N) = -C/4 < 0\). Similarly, \(\Psi(N) - \psi(N) = Ce^{-2N}/2 - Ce^{-4N}/4 < 0\). Therefore, \(\Psi - \psi\) is negative on \([-N, N]\). In fact, it is bounded away from zero.
\end{proof}

\begin{lemma}
    \label{lem:limit-gauge}
    The \(h_N\) converges in the \(C^\infty\) topology on compact subsets, to a smooth path \(h : \R \to \mcH\), such that

    \begin{enumerate}[(i)]
        \item \(h\) is bounded, and for large \(t\), \[\abs{h(t) - 1} \le C'e^{-2t}\] for some \(C' > 0\),
        \item if \(g = h^{1/2}\), \((\alpha', \beta') = g \vdot (\alpha, \beta)\), then \(\hat F(\alpha', \beta') = 0\),
        \item the derivative \(\dv*{h}{t}\) is bounded, and for large \(t\), \[\abs{\dv{h}{t}} < C''e^{-2t}\] for some \(C'' > 0\)
    \end{enumerate}
\end{lemma}

\begin{proof}
    Omitted.
\end{proof}

Using this, we can prove:

\begin{proposition}
    \label{prop:real-trajectory-existence}

    For every complex trajectory \((\alpha, \beta)\), there is an equivalent trajectory \((\alpha', \beta') = g \vdot (\alpha, \beta)\) which satisfies the real equation \(\hat F(\alpha', \beta') = 0\).
\end{proposition}

\begin{proof}
    Using \(g\) from \cref{lem:limit-gauge}, we all we need to show is that \((\alpha', \beta')\) satisfy the boundary conditions \cref{eq:complex-trajectory-boundary-conditions}. First of all, using \cref{lem:limit-gauge} (iii), we find that \((\alpha', \beta') - (\alpha, \beta)\) decays exponentially as \(t \to \infty\). In particular, this means that the boundary conditions at \(t \to \infty\) are satisfied.

    For the boundary conditions at \(t \to -\infty\), split \((\alpha', \beta')\) into hermitian and skew-hermitian parts, to get a solution \((A_0, A_1, A_2, A_3)\) of the extended gradient flow equations \cref{eq:gradient-flow-system-extended}. Using a real gauge transformation \(g \in \mcG\), we can make \(A_0 = 0\), which gives us a solution \((A_1', A_2', A_3')\) of the gradient flow equations \cref{eq:gradient-flow-system}. By \cref{lem:limit-gauge} (iii), this is a bounded trajectory. Therefore, it approaches a critical point. Hence the boundary conditions at \(t \to -\infty\) are satisfied, although it might be for a different representation \(\rho_-\). However, by \cref{lem:complex-trajectory-convergence-negative}, the conjugacy class of the representation \(\rho_-\) given in the limit, is uniquely determined by the orbit in which \(\beta'\) lies, which is the same orbit as \(\beta\).
\end{proof}

\section{Proof of \cref{thm:main}}

Suppose \(A(t)\) is a solution to the gradient flow equations \cref{eq:gradient-flow-system} satisfying the boundary conditions \cref{eq:boundary-conditions}. Setting \(A_0 = 0\), we obtain a complex trajectory \((\alpha, \beta)\). The only thing we need to check that the convergence at \(t \to \pm\infty\) is exponential. But \cref{eq:gradient-flow-system} is an autonomous system, and so the convergence rate of its linearisation is exponential, e.g. by diagonlising the linearisation. Near the fixed points \(\rho_+\) and \(g\rho_-g^{-1}\), the fact that the gradient flow converges implies that it must converge exponentially.

Therefore, we have a map from \(M(\rho_-, \rho_+)\) to the space of equivalence classes of complex trajectories. 

\Cref{prop:real-equation-uniqueness} shows that this map is injective. To see this, suppose \(A, A' \in M(\rho_-, \rho_+)\) give equivalent complex trajectories. Then there exists \(g : \R \to \SU(n)\), with \(g \vdot A = A'\), and \(g(t) \to 1\) as \(t \to \infty\). But in this case, \(A_0 = A_0' = 0\), which means that

\[-\dot g g^{-1} = 0 \implies \dot g = 0\]

and so \(g(t) = 1\) for all \(t\). That is, \(A = A'\).

By \cref{prop:real-trajectory-existence}, in each equivalence class there is a complex trajectory \((\alpha', \beta')\) satisfying the real equation. Decomposing \((\alpha', \beta')\) into hermitian and skew-hermitian parts, we get a solution \((A_0, A_1, A_2, A_3)\) of the extended equations \cref{eq:gradient-flow-system-extended}. Moreover, \(A_0\) decays exponenitally, so there exists a real gauge transformation \(g : \R \to \SU(n)\), with \(g(t) \to 1\) as \(t \to 1\), such that

\[gA_0g^{-1} - \dot g g^{-1} = 0\]

Therefore, from this, we obtain a solution to the original equations. Thus, the map from \(M(\rho_-, \rho_+)\) to the space of equivalence classes of complex trajectories is surjective.

\label{sec:proof}

\section{Nilpotent orbit}

As we are predominantly interested in the nilpotent orbits, we will consider the case where \(\rho_+ = 0\). Define \(M(\rho) = M(\rho, 0)\) to be the space of solutions to \cref{eq:gradient-flow-system}, satisfying the boundary conditions

\[\lim_{t \to -\infty}A(t) \in C(\rho) \qquad \lim_{t \to \infty}A(t) = 0\]

In this case, \cref{thm:main} becomes

\[M(\rho) \cong \mcN(\rho)\]

First of all, given \(A = (A_1, A_2, A_3) \in M(\rho)\), we send it to the equivalence class of the complex trajectory

\[\alpha = iA_1 \qquad \beta = A_2 + iA_3\]

Putting \((\alpha, \beta)\) into the form of \cref{eq:complex-trajectory-form}, we have that

\begin{equation}
    \begin{split}
        \alpha(t) &= \begin{cases}
            \frac12H & t \le 0 \\
            0 & t \ge 1
        \end{cases} \\
        \beta(t) &= \begin{cases}
            Y & t \le 0 \\
            e^{-2t}\epsilon & t \ge 1
        \end{cases}
    \end{split}
\end{equation}

where \(\epsilon\) is conjugate to \(Y\), i.e. \(\epsilon \in \mcN(\rho)\). Note however in this case, we don't need to use \cref{lem:complex-trajectory-convergence-negative} for \(t \le 0\), we could just leave it as is, and just use \cref{lem:complex-trajectory-convergence-positive}. Therefore, to compute \(\epsilon\), we can just solve the ODE

\begin{align*}
    \dot g &= 2g\alpha = 2igA_1 \\
    \lim_{t \to \infty}g(t) &= 1
\end{align*}

and in this case, \(g\) will transform \(\beta\) to \(e^{-2t}\epsilon\) for some \(\epsilon \in \sl(n, \C)\). More precisely, \(\epsilon = g(0)\beta(0)g(0)^{-1}\).

\subsection{Nahm's equations}

Consider the complex equation for Nahm's equations, that is, using the change of variables

\[s = -\frac12e^{-2t} \qquad \tilde\alpha = e^{2t}\alpha \qquad \tilde\beta = e^{2t}\beta\]

we have the complex equation

\[\dv{\tilde\beta}{s} + 2[\tilde\alpha, \tilde \beta] = 0\]

The tangent space to the adjoint orbit \(M\) of \(\tilde\beta\) at \(\tilde\beta\) is

\[\left\{[X, \tilde\beta] \mid X \in \sl(n, \C)\right\}\]

which means that \(\dv{\tilde{\beta}}{s} \in \TT_{\tilde\beta}M\). Therefore \(\tilde\beta\) stays in the same adjoint orbit of \(\sl(n, \C)\). We can transfer this back to the original equations, since for a \emph{nilpotent} matrix \(A\), \(A\) and \(\lambda A\) are conjugate, for all \(\lambda \in \C\). That is, \(\beta\) stays within the same nilpotent orbit.

\subsection{Boundary conditions to Nahm's equations}

\label{subsec:nahm-boundary-conditions}

In this case, we would like to translate the boundary conditions from \(A = (A_1, A_2, A_3)\) to boundary conditions on \(T = (T_1, T_2, T_3)\), where \(T = e^{2t}A\).

The boundary condition \(A \to 0\) at \(t \to \infty\) becomes

\[e^{-2t}T \to 0 \implies sT \to 0\]

as \(s \to 0\). The boundary condition \(\lim\limits_{t \to -\infty}A(t) \in C(\rho)\) becomes

\[\lim_{s \to -\infty}e^{-2t}T \in C(\rho) \implies \lim_{s \to -\infty}sT \in -\frac12 C(\rho)\]

That is, we have the boundary conditions

\begin{equation}
    \label{eq:nahm-boundary-conditions}
    \begin{split}
        \lim_{s \to 0} s T &= 0 \\
        \lim_{s \to -\infty}sT &\in C(\sigma)
    \end{split}
\end{equation}

where \(\sigma = (\sigma_1, \sigma_2, \sigma_3) = -\frac12\rho\) satisfies

\begin{align*}
    [\sigma_1, \sigma_2] &= \sigma_3 \\
    [\sigma_2, \sigma_3] &= \sigma_1 \\
    [\sigma_3, \sigma_1] &= \sigma_2
\end{align*}

In particular, given such a triple, define

\begin{equation}
    \label{eq:nahm-asymptotic-solution}
    T_i = \frac{\sigma_i}{s-1}
\end{equation}

Then this is a solution to Nahm's equations, satisfying the boundary conditions \cref{eq:boundary-conditions}. In fact, all solutions will be asymptotic to (a conjugate of) this one as \(s \to -\infty\).

\subsection{Map for \(\epsilon\) using Nahm's equations}

Setting \(\tilde\alpha = e^{2t}\alpha\) and \(\tilde\beta = e^{2t}\beta\), then we have the complex equation coming from Nahm's equations, i.e.

\[\dv{\tilde\beta}{s} + [\tilde\alpha, \tilde\beta] = 0\]

Therefore, if we instead solve for \(g \vdot (\tilde\alpha, \tilde\beta) = (0, \tilde\beta')\), i.e.

\[\dv{g}{s} = 2g\tilde\alpha\]

with the boundary condition that \(g \to 1\) as \(s \to 0\), then \(\tilde\beta'\) is constant, and this constant is exactly \(\epsilon\). In fact, this is the same equation as in \cref{lem:complex-trajectory-convergence-positive}, just with a change of variables. Therefore, in this case,

\[\tilde\beta(t) = g(t)^{-1}\epsilon g(t)\]

and since \(g(t) \to 1\) as \(s \to 0\), we have that

\[\epsilon = \lim_{s \to 0}\tilde\beta(s)\]

Substituting in the definitions of \(s\) and \(\tilde\beta\), we get that

\[\epsilon = \lim_{t \to \infty}e^{2t}\beta(t)\]

We can do this explicitly for the solution \cref{eq:nahm-asymptotic-solution}. In this case, we have the equation

\[\dot g = g \cdot \frac{2i\sigma_1}{s-1}\]

Suppose \(g(s) = \exp(\gamma(s))\), for some \(\gamma : (-\infty, 0) \to \sl(n, \C)\). In this case,

\[\dot g = g \cdot \dot\gamma\]

Therefore, we want \(\dot\gamma = \dfrac{2i\sigma_1}{s-1}\). Integrating, we find that

\[\gamma(s) = 2i\log(1-s)\sigma_1 + c\]

Substituting this in, we get that

\[g(s) = A\exp(2i\log(1-s)\sigma_1)\]

In fact, the expression above is well defined for \(s \in (-\infty, 1)\). In this case, \(g(0) = A\), and we want \(g(0) = 1\), therefore, \(A = 1\). i.e. 

\[g(s) = \exp(2i\log(1-s)\sigma_1)\]

If we set \(\tilde\beta = T_2 + iT_3\), then \(g\tilde\beta g^{-1}\) is constant, and in fact it is just

\[\tilde\beta(0) = -(\sigma_2 + i\sigma_3)\]

\section{Decomposition}

In the proof, when splitting the gradient flow equations \cref{eq:gradient-flow-system} into the real (\cref{eq:real-equation}) and complex (\cref{eq:complex-equation}) equations, we made a choice to make \(A_1\) ``special''. However, any cyclic permutation of \(A_1, A_2, A_3\) will leave \cref{eq:gradient-flow-system} invariant. Say instead we choose

\[\tilde\alpha = \frac12(A_0 + iA_2) \qquad \tilde\beta = \frac12(A_3 + iA_1)\]

The real and complex equations are invariant, since the gradient flow equations are invariant under cyclic permutations. That is, we have

\begin{align*}
    \hat F(\tilde\alpha, \tilde\beta) = \dv{t}(\tilde\alpha + \tilde\alpha^*) + 2(\tilde\alpha + \tilde\alpha^*) + 2([\tilde\alpha, \tilde\alpha^*] + [\tilde\beta, \tilde\beta^*]) &= 0\\
    \dv{\tilde\beta}{t} + 2\tilde\beta + 2[\tilde\alpha, \tilde\beta] &= 0 
\end{align*}

In this case, given Lie algebra homomorphisms \(\rho_-, \rho_+ : \su(2) \to \su(n)\), we have the corresponding elements

\begin{align*}
    \tilde H_\pm = \rho_\pm(ie_2) &= \rho_\pm\begin{pmatrix}
        0 & i \\
        -i & 0
    \end{pmatrix} \\
    \tilde X_\pm = \rho_\pm\left(\frac{1}{2}(e_3 + ie_1)\right) &= \rho_\pm\begin{pmatrix}
        1 & -i \\
        -i & -1
    \end{pmatrix} \\
    \tilde Y_\pm = \rho_\pm\left(\frac12(-e_3 + ie_1)\right) &= \rho_\pm\begin{pmatrix}
        1 & i \\
        i & -1
    \end{pmatrix}
\end{align*}

In this case (for the nilpotent orbits), we will get an element \(\epsilon\) which is in the same \(\SL(n, \C)\) orbit as \(\tilde Y_-\).

\textbf{TODO: Is this the same orbit as \(Y_-\)?}

\chapter{HyperK\"ahler manifold structure}

In this chapter, we will construct the hyperK\"ahler manifold structure on \(M(\rho)\), following \cite{kronheimer_hyper-kahlerian_1990}. Note however that \cite{kronheimer_hyper-kahlerian_1990} is for the \emph{regular semisimple} orbit, therefore to transfer it to the nilpotent orbit, we will need to make some changes.

\section{Nahm's equations}

Recall that if we set \(B = e^{2t}A\) and \(s = -\frac12e^{-t}\), then the equations \cref{eq:gradient-flow-system} becomes Nahm's equations

\begin{equation}
    \label{eq:nahm}
    \begin{split}
        \dv{B_1}{s} + [B_2, B_3] &= 0 \\
        \dv{B_2}{s} + [B_3, B_1] &= 0 \\
        \dv{B_3}{s} + [B_1, B_2] &= 0
    \end{split}
\end{equation}

and from \cref{subsec:nahm-boundary-conditions}, we have the boundary conditions

\begin{align*}
    \lim_{s \to 0}sB &= 0 \\
    \lim_{s \to -\infty}sB &\in C(\sigma)
\end{align*}

where \(\sigma = -\frac12\rho\), satisfies

\begin{align*}
    [\sigma_1, \sigma_2] &= \sigma_3 \\
    [\sigma_2, \sigma_3] &= \sigma_1 \\
    [\sigma_3, \sigma_1] &= \sigma_2
\end{align*}

Moreover, since we assume the limits \(s \to 0\) exists, we will consider the equations on the half interval \(\Ioc{-\infty, 0}\).

Adding in a fourth function \(B_0 : \Ioc{-\infty, 0} \to \su(n)\), we can write the extended Nahm's equations as

\begin{equation}
    \label{eq:extended-nahm}
    \begin{split}
        \dv{B_1}{s} + [B_0, B_1] + [B_2, B_3] &= 0 \\
        \dv{B_2}{s} + [B_0, B_2] + [B_3, B_1] &= 0 \\
        \dv{B_3}{s} + [B_0, B_3] + [B_1, B_2] &= 0
    \end{split}
\end{equation}

We have three equations for four variables, so the system is underdetermined. We can introduce the gauge group as before, with

\begin{align*}
    \mcG &= \left\{g : \Ioc{-\infty, 0} \to \su(n)\right\} \\
    % \mcG^c &= \left\{g : \Ioc{-\infty, 0} \to \sl(n, \C)\right\}
    \mcG_0 &= \left\{g : \Ioc{-\infty, 0} \to \su(n), g(0) = 1\right\}
    % \mcG_0^c &= \left\{g : \Ioc{-\infty, 0} \to \sl(n, \C), g(0) = 1\right\}
\end{align*}

with the action given by

\[g \vdot (B_0, B_1, B_2, B_3) := \left(gB_0g^{-1} - \dv{g}{s}g^{-1}, gB_1g^{-1}, gB_2g^{-1}, gB_3g^{-1}\right)\]

Using this, if we ignore the boundary conditions, then the space of solutions to \cref{eq:nahm} are the same as the space of solutions to \cref{eq:extended-nahm} modulo the action of \(\mcG_0\), since we can always use \(\mcG_0\) to make \(B_0 = 0\). Moreover, by an element of \(\mcG_0\), we can assume that \(\lim_{s \to -\infty}sB = \sigma\). Let

\[B^0 = \left(0, \frac{\sigma_1}{s-1}, \frac{\sigma_2}{s-1}, \frac{\sigma_3}{s-1}\right)\]

be the ``trivial'' solution to Nahm's equations. We are interested in solutions which are asymptotic to this one. To do this, let \(\Omega_1\) denote the space of all \(C^1\) maps

\[b = (b_0, b_1, b_2, b_3) : \Ioc{-\infty, 0} \to \su(n) \otimes \R^4\]

The boundary conditions on \(M(\rho)\) gives us a norm condition, which is

\[\norm{b}_\delta = \sup_{s \le 0}((1-s)^{1+\delta}\abs{b_j}) + \sup_{s\le0}((1-s)^{2+\delta}\abs{\dot b_j}) < \infty\]

for some \(\delta > 0\), and let

\[\msA = B^0 + \Omega_1 = \left\{B^0 + b \mid b \in \Omega_1\right\}\]

Then all of the solutions which we are interested in belong to \(\msA\). For any path \(u : \Ioc{-\infty, 0} \to \su(n)\), define

\[\grad_B u = \left(\dv{u}{s} + [B_0, u], [B_1, u], [B_2, u], [B_3, u]\right)\]

and we have that

\[M(\rho) \cong \left\{B \in \msA \text{ satisfying \cref{eq:extended-nahm}}\right\}/\msG\]

where \(\msG\) is the group

\[\msG = \left\{g : \Ioc{-\infty, 0} \to \SU(n) \mid g(0) = 1, g^{-1}\grad_Bg \in \Omega_1\right\}\]

The condition \(g^{-1}\grad_Bg \in \Omega_1\) just means that \(g\) carries \(B\) to another element of \(\msA\).

\section{HyperK\"ahler structure on \(\Omega_1\)}

\(\Omega_1\) inherits a natural quaternionic structure from \(\R^4 \cong \bb H\), and we have a norm defined by \(\Omega_1 \subseteq L^2\). That is, we have the \(L^2\) inner product

\[\iinner{b, c} = \sum_{j=0}^3\int_{-\infty}^0 \inner{b_j(s), c_j(s)}\dd s\]

and the complex structures are given by

\begin{align*}
    I(b_0, b_1, b_2, b_3) &= (-b_1, b_0, -b_3, b_2) \\
    J(b_0, b_1, b_2, b_3) &= (-b_2, b_3, b_0, -b_1) \\
    K(b_0, b_1, b_2, b_3) &= (-b_3, -b_2, b_1, b_0)
\end{align*}

Since \(\msA\) is an affine space modelled on \(\Omega\), this means that \(\msA\) inherits a natural hyperK\"ahler structure.

\subsection{Integrability}

A priori, it is not clear that \(\Omega_1\) is a subspace of \(L^2\). However, from the decay condition, we have that

\[\abs{b(s)}^2 \le K \abs{s}^{-2}\]

for some \(K > 0\). The integral

\[\int_{-\infty}^{-1}\frac{1}{x^2}\dd x\]

is finite, and elements of \(\Omega_1\) are bounded on \([-1, 0]\). Therefore, they are in \(L^2\). In fact, the decay condition shows that the elements are also in \(L^1\).

\section{Tangent space}

Let \(\grad_B^*\) be the \(L^2\) adjoint of \(\grad_B\), i.e.

\[\grad_B^*u = - \dv{u_0}{s} - \sum_{j=0}^3[B_j, u_j]\]

Using this, we have

\begin{proposition}
    \label{prop:tangent-space} \(M(\rho)\) is a smooth manifold, and the tangent space to \(M\) at a (the equivalence class) of a solution 
    
    \[B = (B_0(s), B_1(s), B_2(s), B_3(s))\] 
    
    to \cref{eq:extended-nahm} can be identified with the set of solutions in \(\Omega\) of the linear equations

    \begin{equation}
        \label{eq:tangent-space}
        \begin{split}
            \dv{b_0}{s} + [B_0, b_0] + [B_1, b_1] + [B_2, b_2] + [B_3, b_3] &= 0 \\
            \dv{b_1}{s} + [B_0, b_1] - [B_1, b_0] + [B_2, b_3] - [B_3, b_2] &= 0 \\
            \dv{b_2}{s} + [B_0, b_2] - [B_1, b_3] - [B_2, b_0] + [B_3, b_1] &= 0 \\
            \dv{b_3}{s} + [B_0, b_3] + [B_1, b_2] - [B_2, b_1] - [B_3, b_0] &= 0
        \end{split}
    \end{equation}

    Equivalently, it is given by the equation

    \[\grad^*_B(b) = \grad^*_B(Ib) = \grad^*_B(Jb) = \grad^*_B(Kb) = 0\]
\end{proposition}

Using this, the tangent space to \(M\) at \(B\) is a subspace of \(\Omega\), which is invariant under \(I, J, K\). Therefore, \(M\) inherits three almost complex structures satisfying the quaternionic relations. In fact, this and the \(L^2\) metric on \(\Omega\) makes \(M\) into a hyperK\"ahler manifold.

We will sketch how to modify the proof of \cite[Lemma 3.8]{kronheimer_hyper-kahlerian_1990} to this case, as it will then imply the above proposition, using the same proof.

The space \(\Omega_0\) can be defined as in the paper, i.e.

\[\Omega_0 = \left\{u \mid u(0) = 0, \grad_Bu \in \Omega_1 \text{ for some }B \in \msA\right\}\]

with norm \(\norm{u}_0 = \norm{\grad_Bu}_\delta\) and we can define

\[\Omega_0' = \left\{v \ \bigg\vert\  \norm{v}_\delta' = \sup_s((1-s)^{2+\delta}\abs{v(s)}) < \infty\right\}\]

We are interested in the operator

\begin{align*}
    \grad_B^*\grad_B(u) &= \grad_B^*\left(\dv{u}{s} + [B_0, u], [B_1, u], [B_2, u], [B_3, u]\right) \\
    &= -\dv{s}(\dv{u}{s} + [B_0, u]) - \left[B_0, \dv{u}{s}\right]- \sum_{j=0}^3[B_j, [B_j, u]]
\end{align*}

Considering the case \(B = B^0\), we get the equation

\[\dv[2]{u}{s} - \frac{1}{(s-1)^2}\Lambda u = -v\]

where \(\Lambda\) is the nonnegative self-adjoint operator

\[\Lambda u = \sum_{j=0}^3 [\sigma_j^*, [\sigma_j, u]]\]

\(\Lambda\) is diagonalisable, and so we have the equations

\[\ddot u - \frac{\lambda^2}{(s-1)^2}u = v\]

As in \cite{kronheimer_hyper-kahlerian_1990}, we now consider the case where \(v\) is compactly supported. Define \(f(s) = (1-s)^\delta u(s)\). Consider a maxima of \(f\), so \(s_0\) such that \(f'(s_0) = 0\), \(f''(s_0) \le 0\). Computing, we find that

\[u''(s_0) - \frac{\delta(\delta+1)}{(1-s_0)^2}u(s_0) \le 0\]

Using the equation for \(u''\), we then get the equation that

\[\frac{\lambda^2 - \delta(\delta+1)}{(1-s_0)^2}u(s_0) \le v(s_0)\]

Since \(\lambda > 0\), for \(\delta\) sufficiently small, \(\lambda^2 - \delta(k+1) > 0\). In this case, we find that

\[f(s_0) \le K(1-s_0)^{\delta+2}v(s_0)\]

and at a minima, we have the reverse inequality. Therefore, we must have that

\[\sup_s\left((1-s)^\delta\abs{u(s)}\right) \le K\sup_s\left((1-s)^{2+\delta}\abs{v(s)}\right)\]

for some constant \(K\) which is independent of \(v\).

\subsection{The norm on \(\Omega_0\)}

Here, we will compute the norm on \(\Omega_0\), using \(B = B^0\). In particular, we have that

\[\grad_Bu = \left(\dv{u}{s}, \frac{1}{s-1}[\sigma_1, u], \frac{1}{s-1}[\sigma_2, u], \frac{1}{s-1}[\sigma_3, u]\right)\]

The first term gives us

\[(1-s)^{1+\delta}\abs{\dv{u}{s}} \qqtext{and} (1-s)^{2+\delta}\abs{\dv[2]{u}{s}}\]

The rest of the terms are bounded by

\[\frac{(1-s)^{1+\delta}}{s-1} K \abs{u} \le K'(1-s)^\delta\abs{u}\]

for some constant \(K'\) independent of \(u\). For the derivative, we have the terms

\begin{align*}
    \frac{(1-s)^{2 + \delta}}{(1-s)^2}[\sigma_1, u] &\le C(1-s)^\delta\abs{u} \\
    \frac{(1-s)^{2 + \delta}}{1-s}\left[\sigma_1, \dv{u}{s}\right] & \le C'(1-s)^{1+\delta}\abs{\dv{u}{s}}
\end{align*}

Therefore, to bound the norm on \(\Omega_0\), all we need is a bound on

\begin{align*}
    (1-s)^\delta\abs{u(s)} \\
    (1-s)^{1+\delta}\abs{\dv{u}{s}} \\
    (1-s)^{2 + \delta}\abs{\dv[2]{u}{s}}
\end{align*}

\subsection{Bounded below}

Above, we already have a bound on \((1-s)^{\delta}\abs{u(s)}\) from the \(\Omega_0'\) norm of \(v\). In this subsection, we will compute bounds on the derivatives, and show that the operator \(\grad_B^*\grad_B : \Omega_0 \to \Omega_0'\) is bounded below. In particular, this means that we can use density to extend our arguments above to all of \(\Omega_0'\), since the image of an operator which is bounded below is closed. Moreover, since it is a bijection (injectivity follows from the same reason as in \cite{kronheimer_hyper-kahlerian_1990}), the inverse is then a bounded linear map.

The bound on \((1-s)^{2+\delta}\abs{\dv*[2]{u}{s}}\) follows from the ODE and the \(\Omega_0'\) bound on \(v\). Therefore, all we need is a bound on \((1-s_0)^{1+\delta}\abs{\dv*{u}{s}}\). But this follows from a similar argument to the above. Set \(g(s) = (1-s)^{1+\delta}u'(s)\). Then at a maxima/minima of \(g\),

\[g'(s_0) = (1-s_0)^{1+\delta}u''(s_0) - (1+\delta)(1-s_0)^\delta u'(s_0) = 0\]

and so

\[u'(s_0) = \frac{1-s_0}{1+\delta}u''(s_0)\]

which means that

\[(1-s_0)^{1+\delta}u'(s_0) = \frac{(1-s_0)^{2+\delta}}{1+\delta}u''(s_0)\]

Hence the bound on the second derivative gives us a bound on the first derivative.

\section{Adjoint orbit}

Define a map \(\phi : M(\rho) \to \msN\) by

\[\phi(B) = B_2(0) + iB_3(0)\]

and from the previous section, we have that \(\phi(B)\) is in the same adjoint orbit as \(Y\). In terms of the complex coordinates

\[\alpha(s) = \frac12(B_0(s) + iB_1(s)) \qquad \beta(s) = \frac12(B_2(s) + iB_3(s))\]

and a tangent vector \((\delta\alpha, \delta\beta) = (b_0, b_1, b_2, b_3)\), the complex structure \(I\) is just

\[I(\delta\alpha, \delta\beta) = (i\delta\alpha, i\delta\beta)\]

In this case, \(\phi(\alpha, \beta) = 2\beta(0)\), and \(\phi\) can easily be extended to \(\msA\), as

\[\phi(B_0, B_1, B_2, B_3) = B_2(0) + iB_3(0)\]

Hence

\begin{align*}
    \phi(B + b) &= \phi(B_0 + b_0, B_1 + b_1, B_2 + b_2, B_3 + b_3) \\
    &= B_2(0) + b_2(0) + iB_3(0) + ib_3(0) \\
    &= \phi(B) + b_2(0) + ib_3(0) 
\end{align*}

and so, \(\dd\phi_B(b) = b_2(0) + ib_3(0)\). Therefore, in this case we have that \(\phi\) is holomorphic with respect to the complex structures \(I\) on \(M(\rho)\) and \(i\) on the adjoint orbit (which as a complex submanifold of \(\sl(n, \C)\) is naturally K\"ahler).

However, we already have an expression of the tangent space of the adjoint orbit of \(A\), which is

\[\T_A\mcO = \left\{[A, X] \mid X \in \sl(n, \C)\right\}\]

and so, we would like to relate \(\dd\phi_B(b) = b_2(0) + ib_3(0)\) to a Lie bracket with \(\phi(B) = B_2(0) + iB_3(0)\).

\section{At a particular solution}

\textbf{TODO: We changed the definition of the norm to be \(\abs{s}^{1 + \delta}\), so I think the \(\lambda \le -1\) should be \(\lambda \le -1 - \delta\)?}

Now, we would like to compute the tangent space at the solution given by \(B^0\). In this case, we can write the system as

\begin{equation}
    \label{eq:particular-solution-ode}
    \dot b = \frac{1}{1-s}Zb
\end{equation}

where \(Z\) is a fixed linear map, which has \emph{complex} coefficients, as we will consider \(b = (b_0 + ib_1, b_2 + ib_3) \in \sl(n, \C) \oplus \sl(n, \C)\). Suppose \(v\) is an eigenvector of \(Z\), with eigenvalue \(\lambda\). Say \(b = fv\). Then \cref{eq:particular-solution-ode} gives us

\[\dot f v = \frac{\lambda f}{1-s}v\]

Integrating this, we find that

\[f(s) = A(1-s)^\lambda\]

Since \(v\) is only chosen up to a scalar multiple, without loss of generality, we may assume \(A = 1\), so \(f(s) = (1-s)^\lambda\). In this case,

\[\norm{b}_1 = K\sup_{s \le 0}\abs{s(1-s)^\lambda}\]

which is finite if and only if \(\Re(\lambda) \le 1\). More generally, consider a cyclic subspace, i.e. \(v_1, \dots, v_m\) linearly independent, with

\begin{align*}
    v_0 &= 0 \\
    Mv_k &= \lambda v_k + v_{k-1}
\end{align*}

and suppose we wanted to consider solutions of the form

\[b = \sum_{j=1}^m f_jv_j\]

Differentiating componentwise, we have that

\[\dot b = \sum_{j=1}^m \dot f_jv_j\]

On the other hand, \cref{eq:particular-solution-ode} gives us that

\begin{align*}
    \dot b &= \sum_{j=1}^m \frac{f_j}{1-s}(\lambda v_j + v_{j-1}) \\
    &= \sum_{j=1}^m\frac{\lambda f_j + f_{j+1}}{s-1}v_j
\end{align*}

where we set \(f_{m+1} = 0\). In particular, this means that we must have that

\[\dot f_j = \frac{\lambda f_j + f_{j+1}}{1-s}\]

In the case \(m = 2\), as above, we have that

\[f_2(s) = (1-s)^\lambda\]

and we have the ODE

\[(1-s)\dv{f_1}{s} = \lambda f_1 + (1-s)^\lambda\]

which has solution

\[f_1(s) = A(1-s)^{-\lambda} - \frac{(1-s)^\lambda}{2\lambda}\]

Since we already have that \(\Re(\lambda) \le -1\), the only way for \(\abs{s f_1(s)}\) to be bounded is if \(A = 0\). That is,

\[f_1(s) = -\frac{(1-s)^\lambda}{2\lambda}\]

In general, we have a solution of the form

\[f_j(s) = (-2\lambda)^j(1-s)^\lambda\]

for \(\lambda \le -1\). The initial value in this case is

\[f_j(0) = (-2\lambda)^j(1)^\lambda = (-2\lambda)^j\]

Finally, we note that every solution can be written as a sum of ``cyclic'' solutions as above, since we can put \(Z\) into Jordan normal form. Moreover, using linear combinations of the above solutions, we find that the space of boundary values \(b(0)\) which we are interested in is precisely the (cyclic) vectors of \(Z\) associated with the eigenvalues with \(\Re(\lambda) \le -1\).

% \[f_1(s) = A(1-s)^{-\lambda}-\frac{()}\]
% \textbf{TODOs}

% \begin{enumerate}
%     \item Figure out the norm conditions on \(\Omega\),
%     \item Relate the conditions to the boundary conditions \(b(0) \in \su(n) \otimes \R^4\),
%     \item Write down the subspace of \(\su(n) \otimes \R^4\) which we get,
%     \item Compute the complex structures on the adjoint orbit using this.
% \end{enumerate}

% Next, note that 

% \[\dd\phi_B(Jb) = \dd\phi_B(-b_2, b_3, b_0, -b_1) = b_0(0) - ib_1(0)\]

% \textbf{TODO: Compute \(\dd\phi\) (which is just \(\phi\)?) with respect to the tangent space, which is defined as a Lie bracket. Then use this to compute the complex structure \(J\).}

% \emph{The complex symplectic form \(\omega_J + i\omega_K\) on the adjoint orbit from this is the Kirillov-Kostant-Souriau form, which is the same as the Kobak-Swann one. Therefore, all we need to show is that \(J\) is the same in both cases.}

\appendix

\chapter{Prerequisites}

\section{Representation theory of \(\sl(2, \C)\)}

In this section, we will sketch the representation theory of \(\sl(2, \C)\). For more details, see \cite[Section 7]{humphreys}.

Let \(V\) be a complex vector space. Then a representation of \(\sl(2, \C)\) is a Lie algebra homomorphism \(\rho : \sl(2, \C) \to \gl(V)\). When clear, we will write \(X \vdot v := \rho(X)(v)\). Choose the basis

\[X = \begin{pmatrix}
    0 & 1 \\
    0 & 0
\end{pmatrix} \quad Y = \begin{pmatrix}
    0 & 0 \\
    1 & 0
\end{pmatrix} \quad H = \begin{pmatrix}
    1 & 0 \\
    0 & -1
\end{pmatrix}\]

for \(\sl(2, \C)\). The commutators are \([H, X] = 2X, [H, Y] = -2Y, [X,Y] = H\)

We first note that \(\rho(H)\) is diagonalisable, and so we have a Jordan decomposition

\[V = \bigoplus_{\lambda \in \C}V_\lambda\]

where

\[V_\lambda = \left\{v \in V \mid H \cdot v = \lambda v\right\}\]

is the \(\lambda\)-eigenspace of \(H\). In fact, we have:

\begin{enumerate}
    \item \[V = \bigoplus_{\lambda \in \Z}V_\lambda\]
    \item if \(v \in V_\mu\), then \(X \cdot v \in V_{\mu+2}\) and \(Y \cdot v \in V_{\mu-2}\).
\end{enumerate}

\section{Distributions}

\label{sec:distributions}

Let \(\Omega \subseteq \R^n\) be open and connected.

\begin{definition}
    [positive]
    We say that \(u \in \mcD'(\Omega)\) is \emph{positive} if for all \(\phi \in C_c^\infty(\Omega)\), with \(\phi \ge 0\), \(u[\phi] \ge 0\). We write this as \(u \ge 0\). 
\end{definition}

\begin{definition}
    [derivative]

    The derivative of a distribution \(u \in \mcD'(\Omega)\) is the distribution \(Du\) given by

    \[Du[\phi] = -u[D\phi]\]
\end{definition}

Finally, recall that we have an embedding \(T : L^1_\text{loc.}(\Omega) \to \mcD'(\Omega)\), given by

\[T_f(\phi) = \int_\Omega f\phi \dd x\]

We will abuse notation and write \(Df = DT_f\). With this, let

\[L = \sum_{k=0}^d a_k D^k\]

be a linear differential operator, \(a_k : \Omega \to \R\) smooth. Suppose \(Lf \ge 0\). Then we say that the differential inequality \(Lf \ge 0\) holds \emph{weakly}.

\printbibliography

\end{document}
